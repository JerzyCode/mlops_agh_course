{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4decbc",
   "metadata": {},
   "source": [
    "## Lab 04 Vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520b7cb",
   "metadata": {},
   "source": [
    "# PG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31eee60",
   "metadata": {},
   "source": [
    "### Creating db_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa35849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.engine import URL\n",
    "\n",
    "db_url = URL.create(\n",
    "    drivername=\"postgresql+psycopg\",\n",
    "    username=\"postgres\",\n",
    "    password=\"password\",\n",
    "    host=\"localhost\",\n",
    "    port=5432,\n",
    "    database=\"similarity_search_service_db\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eceb43",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f949755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Integer, String\n",
    "from typing import List\n",
    "from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column\n",
    "\n",
    "\n",
    "class Base(DeclarativeBase):\n",
    "    __abstract__ = True\n",
    "\n",
    "\n",
    "class Image(Base):\n",
    "    __tablename__ = \"images\"\n",
    "    VECTOR_LENGTH = 512\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    image_path: Mapped[str] = mapped_column(String(256))\n",
    "    image_embedding: Mapped[List[float]] = mapped_column(Vector(VECTOR_LENGTH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d231631",
   "metadata": {},
   "source": [
    "### Connecting to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc2feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634307f8",
   "metadata": {},
   "source": [
    "### Creating Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5a2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dbe10",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86f37f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def insert_image(\n",
    "    engine: sqlalchemy.Engine, image_path: str, image_embedding: list[float]\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        image = Image(image_path=image_path, image_embedding=image_embedding)\n",
    "        session.add(image)\n",
    "        session.commit()\n",
    "\n",
    "\n",
    "N = 100\n",
    "for i in range(N):\n",
    "    image_path = f\"image_{i}.jpg\"\n",
    "    image_embedding = np.random.rand(512).tolist()\n",
    "    insert_image(engine, image_path, image_embedding)\n",
    "\n",
    "with Session(engine) as session:\n",
    "    image = session.query(Image).first()\n",
    "\n",
    "\n",
    "def find_k_images(\n",
    "    engine: sqlalchemy.Engine, k: int, orginal_image: Image\n",
    ") -> list[Image]:\n",
    "    with Session(engine) as session:\n",
    "        # execution_options={\"prebuffer_rows\": True} is used to prebuffer the rows, this is useful when we want to fetch the rows in chunks and return them after session is closed\n",
    "        result = session.execute(\n",
    "            sqlalchemy.select(Image)\n",
    "            .order_by(\n",
    "                Image.image_embedding.cosine_distance(orginal_image.image_embedding)\n",
    "            )\n",
    "            .limit(k),\n",
    "            execution_options={\"prebuffer_rows\": True},\n",
    "        )\n",
    "        return result\n",
    "\n",
    "\n",
    "k = 10\n",
    "similar_images = find_k_images(engine, k, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f001d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image_0.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(similar_images)[0][0].image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4310c6",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678f0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import select\n",
    "\n",
    "\n",
    "def find_images_with_similarity_score_greater_than(\n",
    "    engine: sqlalchemy.Engine, similarity_score: float, orginal_image: Image\n",
    ") -> list[Image]:\n",
    "    with Session(engine) as session:\n",
    "        result = session.execute(\n",
    "            select(Image).filter(\n",
    "                Image.image_embedding.cosine_distance(orginal_image.image_embedding)\n",
    "                > similarity_score\n",
    "            ),\n",
    "            execution_options={\"prebuffer_rows\": True},\n",
    "        )\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af34c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ChunkedIteratorResult at 0x735775da5590>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image(image_path=\"test_path.jpg\", image_embedding=np.random.rand(512).tolist())\n",
    "\n",
    "find_images_with_similarity_score_greater_than(\n",
    "    engine, similarity_score=0.65, orginal_image=img\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f209c10",
   "metadata": {},
   "source": [
    "## Steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759c7bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e409d636eb354ff495d8acc86de6e4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1c21bb035545579b452130ab8ac94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-e2ed184370a069(â€¦):   0%|          | 0.00/123M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ee46748eea4382aeb30dc3bf002a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/83560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AppID': Value('int64'), 'Name': Value('string'), 'Release date': Value('string'), 'Estimated owners': Value('string'), 'Peak CCU': Value('int64'), 'Required age': Value('int64'), 'Price': Value('float64'), 'DLC count': Value('int64'), 'About the game': Value('string'), 'Supported languages': Value('string'), 'Full audio languages': Value('string'), 'Reviews': Value('string'), 'Header image': Value('string'), 'Website': Value('string'), 'Support url': Value('string'), 'Support email': Value('string'), 'Windows': Value('bool'), 'Mac': Value('bool'), 'Linux': Value('bool'), 'Metacritic score': Value('int64'), 'Metacritic url': Value('string'), 'User score': Value('int64'), 'Positive': Value('int64'), 'Negative': Value('int64'), 'Score rank': Value('float64'), 'Achievements': Value('int64'), 'Recommendations': Value('int64'), 'Notes': Value('string'), 'Average playtime forever': Value('int64'), 'Average playtime two weeks': Value('int64'), 'Median playtime forever': Value('int64'), 'Median playtime two weeks': Value('int64'), 'Developers': Value('string'), 'Publishers': Value('string'), 'Categories': Value('string'), 'Genres': Value('string'), 'Tags': Value('string'), 'Screenshots': Value('string'), 'Movies': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"FronkonGames/steam-games-dataset\")\n",
    "\n",
    "columns = dataset[\"train\"].features\n",
    "print(columns)\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"Name\",\n",
    "    \"Windows\",\n",
    "    \"Linux\",\n",
    "    \"Mac\",\n",
    "    \"About the game\",\n",
    "    \"Supported languages\",\n",
    "    \"Price\",\n",
    "]\n",
    "\n",
    "N = 40000\n",
    "dataset = dataset[\"train\"].select_columns(columns_to_keep).select(range(N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6aa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Integer, Float, Boolean\n",
    "\n",
    "\n",
    "class Games(Base):\n",
    "    __tablename__ = \"games\"\n",
    "    __table_args__ = {\"extend_existing\": True}\n",
    "\n",
    "    # the vector size produced by the model taken from documentation https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2\n",
    "    VECTOR_LENGTH = 512  # check the model output dimensionality\n",
    "\n",
    "    id: Mapped[int] = mapped_column(Integer, primary_key=True)\n",
    "    name: Mapped[str] = mapped_column(String(256))\n",
    "    description: Mapped[str] = mapped_column(String(4096))\n",
    "    windows: Mapped[bool] = mapped_column(Boolean)\n",
    "    linux: Mapped[bool] = mapped_column(Boolean)\n",
    "    mac: Mapped[bool] = mapped_column(Boolean)\n",
    "    price: Mapped[float] = mapped_column(Float)\n",
    "    game_description_embedding: Mapped[List[float]] = mapped_column(\n",
    "        Vector(VECTOR_LENGTH)\n",
    "    )\n",
    "\n",
    "\n",
    "Base.metadata.drop_all(engine)\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94217f4a",
   "metadata": {},
   "source": [
    "### Sentence transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d3e4aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5005654c67c44d2a9459fd3cd4eef341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3069fa4c0a24eb59f5c0de8f80b9c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4d82ff91ab4e4d81e30be56ce4c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a2760c3b104285894d01e25c99be2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e177d247a24fb8ba95a623bfe71c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a08254a3ab42029716bd446bf0acac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9011830539a34d2590a238b72d907e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263e880757a54178a81a5558799f59dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886854790f9e4b39ab328ada01d00641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f976221d40f400f80da4a2e4203aa48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4574174090ce49459ab0b9bd58ee3246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7fa163e2a842d9a484b0f12c485bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a665962cfcff4bd7a0e876c69057e770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/model.safetensors:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "checkpoint = \"distiluse-base-multilingual-cased-v2\"\n",
    "model = SentenceTransformer(checkpoint, device=\"cpu\")\n",
    "\n",
    "\n",
    "def generate_embeddings(text: str) -> list[float]:\n",
    "    return model.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c47a1b2",
   "metadata": {},
   "source": [
    "### Insert games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4092f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def insert_games(engine, dataset):\n",
    "    with tqdm(total=len(dataset)) as pbar:\n",
    "        for i, game in enumerate(dataset):\n",
    "            game_description = game[\"About the game\"] or \"\"\n",
    "            game_embedding = generate_embeddings(game_description)\n",
    "            name, windows, linux, mac, price = (\n",
    "                game[\"Name\"],\n",
    "                game[\"Windows\"],\n",
    "                game[\"Linux\"],\n",
    "                game[\"Mac\"],\n",
    "                game[\"Price\"],\n",
    "            )\n",
    "            if name and windows and linux and mac and price and game_description:\n",
    "                game = Games(\n",
    "                    name=game[\"Name\"],\n",
    "                    description=game_description[0:4096],\n",
    "                    windows=game[\"Windows\"],\n",
    "                    linux=game[\"Linux\"],\n",
    "                    mac=game[\"Mac\"],\n",
    "                    price=game[\"Price\"],\n",
    "                    game_description_embedding=game_embedding,\n",
    "                )\n",
    "                with Session(engine) as session:\n",
    "                    session.add(game)\n",
    "                    session.commit()\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57584ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40000/40000 [1:03:02<00:00, 10.58it/s]\n"
     ]
    }
   ],
   "source": [
    "insert_games(engine, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec063b3",
   "metadata": {},
   "source": [
    "### Find games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1879cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def find_game(\n",
    "    engine: sqlalchemy.Engine,\n",
    "    game_description: str,\n",
    "    windows: Optional[bool] = None,\n",
    "    linux: Optional[bool] = None,\n",
    "    mac: Optional[bool] = None,\n",
    "    price: Optional[int] = None,\n",
    "):\n",
    "    with Session(engine) as session:\n",
    "        game_embedding = generate_embeddings(game_description)\n",
    "\n",
    "        query = select(Games).order_by(\n",
    "            Games.game_description_embedding.cosine_distance(game_embedding)\n",
    "        )\n",
    "\n",
    "        if price:\n",
    "            query = query.filter(Games.price <= price)\n",
    "        if windows:\n",
    "            query = query.filter(Games.windows)\n",
    "        if linux:\n",
    "            query = query.filter(Games.linux)\n",
    "        if mac:\n",
    "            query = query.filter(Games.mac)\n",
    "\n",
    "        result = session.execute(query, execution_options={\"prebuffer_rows\": True})\n",
    "        game = result.scalars().first()\n",
    "\n",
    "        return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3c702ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: Ultimate Spider Hero\n",
      "Description: Ultimate Spider Hero game was designed for real heroes! Your mission is to help poor residents of the Metropolis and to save them from the terrible monsters. Move forward to fight your enemies and try not to fall! Features: Simple and addictive gameplay Nice graphics Awesome Ultimate Spider Hero Countless Steam achievements for you to collect! Compatibility with multiple major platforms (Windows, Mac, Linux, SteamOS) Make your way through the endless labyrinths of long, confusing city streets together with your favorite hero from countless movies and cartoons! Although this may look simple enough, things are not as easy as they seem. You will have to learn how to cling into houses properly using your web, otherwise you will fall to your demise. If you manage to do so - you will become a real superhero, armed with elusiveness, agility and speed and the ability to tirelessly swing across the rooftops and between the huge skyscrapers this urban landscape has to offer in this thrilling game of a super spider. It's fun, the visuals are magnificent and the controls are simple!\n",
      "Game: 3D PUZZLE - Modern House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, \"This is a game about a hero who saves the world\", price=10)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")\n",
    "\n",
    "game = find_game(engine, game_description=\"Home decorating\", price=20)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eae615c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 3D PUZZLE - Old House\n",
      "Description: Collect a 3D puzzle, transferring things to the right places to create a beautiful house. You need to go to the item, take it by pressing the left mouse button and take the item to the desired location marked in green. If you brought the correct item, it will snap into place and you will receive leaderboard points and achievements for this. Collect as much substance as possible as quickly as possible to get more points for the leaderboard. If you brought the wrong item, you can throw it away, it will return to the starting location so that you can pick it up again.\n"
     ]
    }
   ],
   "source": [
    "game = find_game(engine, game_description=\"Home decorating\", mac=True, price=5)\n",
    "print(f\"Game: {game.name}\")\n",
    "print(f\"Description: {game.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd46c7",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3805ec",
   "metadata": {},
   "source": [
    "### Connec to to milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "host = \"localhost\"\n",
    "port = \"19530\"\n",
    "\n",
    "milvus_client = MilvusClient(host=host, port=port)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d295c",
   "metadata": {},
   "source": [
    "### Create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad11e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import FieldSchema, DataType, CollectionSchema\n",
    "\n",
    "VECTOR_LENGTH = 768  # check the dimensionality for Silver Retriever Base (v1.1) model\n",
    "\n",
    "id_field = FieldSchema(\n",
    "    name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"Primary id\"\n",
    ")\n",
    "text = FieldSchema(\n",
    "    name=\"text\", dtype=DataType.VARCHAR, max_length=4096, description=\"Page text\"\n",
    ")\n",
    "embedding_text = FieldSchema(\n",
    "    \"embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=VECTOR_LENGTH,\n",
    "    description=\"Embedded text\",\n",
    ")\n",
    "\n",
    "fields = [id_field, text, embedding_text]\n",
    "\n",
    "schema = CollectionSchema(\n",
    "    fields=fields,\n",
    "    auto_id=True,\n",
    "    enable_dynamic_field=True,\n",
    "    description=\"RAG Texts collection\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac8b93",
   "metadata": {},
   "source": [
    "### Create collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d878102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_texts_and_embeddings']\n",
      "{'collection_name': 'rag_texts_and_embeddings', 'auto_id': True, 'num_shards': 1, 'description': 'RAG Texts collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': 'Primary id', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'text', 'description': 'Page text', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 102, 'name': 'embedding', 'description': 'Embedded text', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 461835363952623831, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': True, 'created_timestamp': 461835374861484038}\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME = \"rag_texts_and_embeddings\"\n",
    "\n",
    "milvus_client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "\n",
    "index_params = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"L2\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64},  # lower values for speed\n",
    ")\n",
    "\n",
    "\n",
    "milvus_client.create_index(collection_name=COLLECTION_NAME, index_params=index_params)\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16954ff4",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fab5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data source and destination\n",
    "## the document origin destination from which document will be downloaded\n",
    "pdf_url = \"https://www.iab.org.pl/wp-content/uploads/2024/04/Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the document\n",
    "file_name = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.pdf\"\n",
    "\n",
    "## local destination of the processed document\n",
    "file_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska.json\"\n",
    "\n",
    "## local destination of the embedded pages of the document\n",
    "embeddings_json = \"Przewodnik-po-sztucznej-inteligencji-2024_IAB-Polska-Embeddings.json\"\n",
    "\n",
    "## local destination of all above local required files\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74989215",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_pdf_data(pdf_url: str, file_name: str) -> None:\n",
    "    response = requests.get(pdf_url, stream=True)\n",
    "    with open(os.path.join(data_dir, file_name), \"wb\") as file:\n",
    "        for block in response.iter_content(chunk_size=1024):\n",
    "            if block:\n",
    "                file.write(block)\n",
    "\n",
    "\n",
    "download_pdf_data(pdf_url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d404b73a",
   "metadata": {},
   "source": [
    "### Preparing and chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import json\n",
    "\n",
    "\n",
    "def extract_pdf_text(file_name, file_json):\n",
    "    document = fitz.open(os.path.join(data_dir, file_name))\n",
    "    pages = []\n",
    "\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        page_text = page.get_text()\n",
    "        pages.append({\"page_num\": page_num, \"text\": page_text})\n",
    "\n",
    "    with open(os.path.join(data_dir, file_json), \"w\") as file:\n",
    "        json.dump(pages, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "extract_pdf_text(file_name, file_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e7919",
   "metadata": {},
   "source": [
    "### Vectorize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def generate_embeddings(file_json, embeddings_json, model):\n",
    "    pages = []\n",
    "    with open(os.path.join(data_dir, file_json), \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    for page in data:\n",
    "        pages.append(page[\"text\"])\n",
    "\n",
    "    embeddings = model.encode(pages)\n",
    "\n",
    "    embeddings_paginated = []\n",
    "    for page_num in range(len(embeddings)):\n",
    "        embeddings_paginated.append(\n",
    "            {\"page_num\": page_num, \"embedding\": embeddings[page_num].tolist()}\n",
    "        )\n",
    "\n",
    "    with open(os.path.join(data_dir, embeddings_json), \"w\") as file:\n",
    "        json.dump(embeddings_paginated, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "model_name = \"ipipan/silver-retriever-base-v1.1\"\n",
    "device = \"cpu\"\n",
    "model = SentenceTransformer(model_name, device=device)\n",
    "generate_embeddings(file_json, embeddings_json, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef39c90",
   "metadata": {},
   "source": [
    "### Insert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "43b9f23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_embeddings(\n",
    "    file_json,\n",
    "    embeddings_json,\n",
    "    client=milvus_client,\n",
    "    collection_name=\"rag_texts_and_embeddings\",\n",
    "):\n",
    "    rows = []\n",
    "    with (\n",
    "        open(os.path.join(data_dir, file_json), \"r\") as t_f,\n",
    "        open(os.path.join(data_dir, embeddings_json), \"r\") as e_f,\n",
    "    ):\n",
    "        text_data, embedding_data = json.load(t_f), json.load(e_f)\n",
    "        text_data = list(map(lambda d: d[\"text\"], text_data))\n",
    "        embedding_data = list(map(lambda d: d[\"embedding\"], embedding_data))\n",
    "\n",
    "        for page, (text, embedding) in enumerate(zip(text_data, embedding_data)):\n",
    "            rows.append({\"text\": text, \"embedding\": embedding})\n",
    "\n",
    "    client.insert(collection_name=collection_name, data=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584a4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_embeddings(file_json, embeddings_json)\n",
    "\n",
    "# load inserted data into memory\n",
    "milvus_client.load_collection(\"rag_texts_and_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbff288f",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "85b466a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    model,\n",
    "    query,\n",
    "    client=milvus_client,\n",
    "    collection_name=\"rag_texts_and_embeddings\",\n",
    "    metric_type=\"L2\",\n",
    "):\n",
    "    embedded_query = model.encode(query).tolist()\n",
    "    result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        data=[embedded_query],\n",
    "        limit=1,\n",
    "        search_params={\"metric_type\": metric_type},\n",
    "        output_fields=[\"text\"],\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d294b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historia powstania\n",
      "sztucznej inteligencji\n",
      "7\n",
      "W jÄ™zyku potocznym â€žsztuczny\" oznacza to, co\n",
      "jest \n",
      "wytworem \n",
      "majÄ…cym \n",
      "naÅ›ladowaÄ‡ \n",
      "coÅ›\n",
      "naturalnego. W takim znaczeniu uÅ¼ywamy\n",
      "terminu ,,sztuczny'', gdy mÃ³wimy o sztucznym\n",
      "lodowisku lub oku. Sztuczna inteligencja byÅ‚aby\n",
      "czymÅ› (programem, maszynÄ…) symulujÄ…cym\n",
      "inteligencjÄ™ naturalnÄ…, ludzkÄ….\n",
      "Sztuczna inteligencja (AI) to obszar informatyki,\n",
      "ktÃ³ry skupia siÄ™ na tworzeniu programÃ³w\n",
      "komputerowych zdolnych do wykonywania\n",
      "zadaÅ„, ktÃ³re wymagajÄ… ludzkiej inteligencji. \n",
      "Te zadania obejmujÄ… rozpoznawanie wzorcÃ³w,\n",
      "rozumienie jÄ™zyka naturalnego, podejmowanie\n",
      "decyzji, uczenie siÄ™, planowanie i wiele innych.\n",
      "GÅ‚Ã³wnym celem AI jest stworzenie systemÃ³w,\n",
      "ktÃ³re sÄ… zdolne do myÅ›lenia i podejmowania\n",
      "decyzji na sposÃ³b przypominajÄ…cy ludzki.\n",
      "Historia sztucznej inteligencji siÄ™ga lat 50. \n",
      "XX wieku, kiedy to powstaÅ‚y pierwsze koncepcje\n",
      "i modele tego, co mogÅ‚oby staÄ‡ siÄ™ sztucznÄ…\n",
      "inteligencjÄ…. Jednym z pionierÃ³w byÅ‚ Alan\n",
      "Turing, ktÃ³ry sformuÅ‚owaÅ‚ test Turinga, majÄ…cy\n",
      "na \n",
      "celu \n",
      "ocenÄ™ \n",
      "zdolnoÅ›ci \n",
      "maszyny \n",
      "do\n",
      "inteligentnego \n",
      "zachowania \n",
      "na \n",
      "poziomie\n",
      "ludzkim. JednakÅ¼e dopiero w latach 80. i 90.\n",
      "nastÄ…piÅ‚ \n",
      "prawdziwy \n",
      "przeÅ‚om \n",
      "w \n",
      "dziedzinie\n",
      "sztucznej \n",
      "inteligencji \n",
      "dziÄ™ki \n",
      "postÄ™powi \n",
      "w\n",
      "dziedzinie algorytmÃ³w uczenia maszynowego.\n",
      "W wypadku sztucznej inteligencji mamy na\n",
      "uwadze system, ktÃ³ry realizowaÅ‚by niektÃ³re\n",
      "funkcje \n",
      "umysÅ‚u \n",
      "â€“ \n",
      "czasami \n",
      "w \n",
      "sposÃ³b\n",
      "przewyÅ¼szajÄ…cy funkcje naturalne (na przykÅ‚ad,\n",
      "aby byÅ‚ wolny od pomyÅ‚ek przy liczeniu oraz\n",
      "defektÃ³w \n",
      "pamiÄ™ci). \n",
      "Inteligencja \n",
      "jest \n",
      "wÅ‚a-\n",
      "Å›ciwoÅ›ciÄ… umysÅ‚u. \n",
      "SkÅ‚ada siÄ™ na niÄ… szereg umiejÄ™tnoÅ›ci, takich jak\n",
      "zdolnoÅ›Ä‡ do komunikowania, rozwiÄ…zywania\n",
      "problemÃ³w, uczenia siÄ™ i dostosowywania do\n",
      "sytuacji. \n",
      "Istotna \n",
      "jest \n",
      "jednak \n",
      "umiejÄ™tnoÅ›Ä‡\n",
      "rozumowania.\n",
      "WspÃ³Å‚czesne systemy sztucznej inteligencji sÄ…\n",
      "inteligentne tylko w ograniczonym obszarze. \n",
      "Na przykÅ‚ad komputer potrafi graÄ‡ w szachy w\n",
      "taki \n",
      "sposÃ³b, \n",
      "Å¼e \n",
      "wygrywa \n",
      "z \n",
      "szachowym\n",
      "arcymistrzem. W 1996 r. Deep Blue wygraÅ‚ jednÄ…\n",
      "partiÄ™ \n",
      "szachÃ³w \n",
      "z \n",
      "Garry \n",
      "Kasparowem,\n",
      "przegrywajÄ…c caÅ‚y mecz wynikiem 4:2 (przy\n",
      "dwÃ³ch remisach).\n",
      "PÃ³Åºniej Deep Blue zostaÅ‚ ulepszony i nie-\n",
      "oficjalnie \n",
      "nazwany \n",
      "â€žDeeper \n",
      "Blue\". \n",
      "ZagraÅ‚\n",
      "ponownie z Kasparowem w maju 1997 roku.\n",
      "Mecz \n",
      "skoÅ„czyÅ‚ \n",
      "siÄ™ \n",
      "wynikiem \n",
      "3Â½:2Â½ \n",
      "dla\n",
      "komputera. W ten sposÃ³b Deep Blue staÅ‚ siÄ™\n",
      "pierwszym systemem komputerowym, ktÃ³ry\n",
      "wygraÅ‚ z aktualnym mistrzem Å›wiata w meczu\n",
      "ze standardowÄ… kontrolÄ… czasu.\n",
      "Å¹rÃ³dÅ‚o: Midjourney â€“ obraz wygenerowany przez AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = search(model, query=\"Czym jest sztuczna inteligencja\")\n",
    "print(result[0][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f08428",
   "metadata": {},
   "source": [
    "### Gemini API integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58336f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "051c63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "gemini_client = genai.Client(api_key=GEMINI_KEY)\n",
    "\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "\n",
    "def generate_response(prompt: str):\n",
    "    try:\n",
    "        response = gemini_client.models.generate_content(\n",
    "            model=MODEL,\n",
    "            contents=prompt,\n",
    "        )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95f42a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt is in polish, because the context is in polish\n",
    "\n",
    "\n",
    "def build_prompt(context: str, query: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "        JesteÅ› ekspertem w dziedzinie Sztucznej Inteligencji i Uczenia Maszynowego.\n",
    "        Na podstawie dostarczonego kontekstu:\n",
    "\n",
    "        {context}\n",
    "\n",
    "        ZnajdÅº odpowiedÅº na nastÄ™pujÄ…ce pytanie:\n",
    "        \n",
    "        {query}\n",
    "\n",
    "        BÄ…dÅº bardzo precyzyjny i nie podawaj Å¼adnych informacji, ktÃ³re nie znajdujÄ… siÄ™ w dostarczonym kontekÅ›cie.\n",
    "        JeÅ›li w kontekÅ›cie nie ma odpowiedzi, odpowiedz \"Nie znaleziono informacji\".\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def rag(\n",
    "    model,\n",
    "    query: str,\n",
    "    collection_nane: str = \"rag_texts_and_embeddings\",\n",
    "    metric_type: str = \"L2\",\n",
    ") -> str:\n",
    "    context = search(\n",
    "        model, query=query, collection_name=collection_nane, metric_type=metric_type\n",
    "    )[0][0][\"text\"]\n",
    "    prompt = build_prompt(context, query)\n",
    "    response = generate_response(prompt)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5330c5",
   "metadata": {},
   "source": [
    "### Having fun with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08f7613c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie znaleziono informacji.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"Czym jest Contrastive Language-Image Pretraining?\"\n",
    "response1 = rag(model, query1)\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c7d83",
   "metadata": {},
   "source": [
    "#### Debug why 'nie znaleziono informacji'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ed255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WielkoÅ›Ä‡ zasobÃ³w internetowych, na podstawie\n",
      "ktÃ³rych LLM rozwija swoje moÅ¼liwoÅ›ci, staje siÄ™\n",
      "coraz wiÄ™ksza, a nad ich jakoÅ›ciÄ… czuwajÄ…\n",
      "twÃ³rcy modelu. PrzeÅ‚omem w ustanawianiu\n",
      "standardÃ³w z zakresu modelowania jÄ™zyka byÅ‚\n",
      "ChatGPT-2, ktÃ³ry pokazaÅ‚, jak zwiÄ™kszenie skali\n",
      "modelu moÅ¼e prowadziÄ‡ do nowych i bardziej\n",
      "zaawansowanych moÅ¼liwoÅ›ci. Te umiejÄ™tnoÅ›ci\n",
      "tworzenia tekstu przez GPT-2 przeÅ‚oÅ¼yÅ‚y siÄ™ na\n",
      "zdolnoÅ›Ä‡ do wytwarzania dÅ‚ugich, spÃ³jnych i\n",
      "kontekstowo poprawnych treÅ›ci, z tworzeniem\n",
      "esejÃ³w, opowiadaÅ„, a nawet poezji wÅ‚Ä…cznie.\n",
      "Model wykazaÅ‚ teÅ¼ zdolnoÅ›Ä‡ do rozumienia i\n",
      "rozwiÄ…zywania \n",
      "bardziej \n",
      "zÅ‚oÅ¼onych \n",
      "zadaÅ„\n",
      "jÄ™zykowych, \n",
      "takich \n",
      "jak \n",
      "rozrÃ³Å¼nianie\n",
      "dwuznacznoÅ›ci \n",
      "w \n",
      "tekstach. \n",
      "Kolejne \n",
      "etapy\n",
      "rozwoju popularnego czatu doprowadziÅ‚y do\n",
      "wersji \n",
      "GPT-4, \n",
      "wykraczajÄ…cej \n",
      "juÅ¼ \n",
      "poza\n",
      "modelowanie jÄ™zykowe i obejmujÄ…cej multi-\n",
      "media.\n",
      "JeÅ›li zastanawiasz siÄ™, dlaczego ciÄ…gle mÃ³wimy\n",
      "o \"przewidywaniu jednego, kolejnego sÅ‚owa\",\n",
      "podczas gdy na przykÅ‚ad czat GPT bez trudu\n",
      "generuje dÅ‚ugie teksty, to odpowiedÅº jest\n",
      "prosta: modele jÄ™zykowe faktycznie generujÄ…\n",
      "dÅ‚ugie teksty, ale robiÄ… to krok po kroku, sÅ‚owo\n",
      "po sÅ‚owie. W rzeczywistoÅ›ci, po wygenerowaniu\n",
      "kaÅ¼dego \n",
      "nowego \n",
      "sÅ‚owa, \n",
      "model \n",
      "ponownie\n",
      "przetwarza caÅ‚y poprzedni tekst wraz z nowo\n",
      "dodanym \n",
      "fragmentem, \n",
      "aby \n",
      "wygenerowaÄ‡\n",
      "kolejne sÅ‚owo. W ten sposÃ³b powstaje spÃ³jna\n",
      "wypowiedÅº.\n",
      "W rzeczywistoÅ›ci duÅ¼e modele jÄ™zykowe (LLM)\n",
      "starajÄ… siÄ™ przewidzieÄ‡ nie tyle konkretne,\n",
      "nastÄ™pne \n",
      "sÅ‚owo, \n",
      "ile \n",
      "prawdopodobieÅ„stwa\n",
      "uÅ¼ycia rÃ³Å¼nych sÅ‚Ã³w, ktÃ³re mogÄ… kontynuowaÄ‡\n",
      "dany tekst. Dlaczego najlepszym rozwiÄ…zaniem\n",
      "nie \n",
      "zawsze \n",
      "jest \n",
      "szukanie \n",
      "\"najbardziej\n",
      "odpowiedniego\" \n",
      "sÅ‚owa? \n",
      "RozwaÅ¼my \n",
      "to \n",
      "na\n",
      "przykÅ‚adzie prostej gry.\n",
      "ZaÅ‚Ã³Å¼my, Å¼e masz kontynuowaÄ‡ tekst: \"44.\n",
      "prezydent USA (i pierwszy Afroamerykanin na\n",
      "tym stanowisku) to Barack...\". JeÅ›li pomyÅ›laÅ‚eÅ›,\n",
      "Å¼e nastÄ™pnym sÅ‚owem powinno byÄ‡ \"Obama\" z\n",
      "prawdopodobieÅ„stwem 100%, to siÄ™ mylisz! W\n",
      "oficjalnych \n",
      "dokumentach \n",
      "imiÄ™ \n",
      "prezydenta\n",
      "czÄ™sto jest podawane w wersji peÅ‚nej, razem z\n",
      "drugim imieniem \"Hussein\". Dlatego dobrze\n",
      "wytrenowany LLM przewidziaÅ‚by \"Obama\" z\n",
      "prawdopodobieÅ„stwem \n",
      "okoÅ‚o \n",
      "90%, \n",
      "pozo-\n",
      "stawiajÄ…c 10% dla \"Hussein\".\n",
      "To obrazuje interesujÄ…cy aspekt LLM â€“ jego\n",
      "twÃ³rczy \n",
      "charakter. \n",
      "Podczas \n",
      "generowania\n",
      "kaÅ¼dego nastÄ™pnego sÅ‚owa, modele wybierajÄ…\n",
      "je \"losowo\" bazujÄ…c na prawdopodobieÅ„stwach\n",
      "wyliczonych \n",
      "podczas \n",
      "treningu \n",
      "na \n",
      "duÅ¼ych\n",
      "zbiorach tekstÃ³w. DziÄ™ki temu, te same modele\n",
      "mogÄ… dawaÄ‡ rÃ³Å¼ne odpowiedzi na identyczne\n",
      "zapytania, podobnie jak ludzie. Eksperymenty\n",
      "pokazaÅ‚y, \n",
      "Å¼e \n",
      "modele \n",
      "wybierajÄ…ce \n",
      "zawsze\n",
      "\"najbardziej prawdopodobne\" sÅ‚owo dziaÅ‚ajÄ…\n",
      "gorzej niÅ¼ te, ktÃ³re wprowadzajÄ… element\n",
      "losowoÅ›ci.\n",
      "JÄ™zyk jest strukturÄ… z zasadami i wyjÄ…tkami, a\n",
      "sÅ‚owa w zdaniach sÄ… ze sobÄ… powiÄ…zane. \n",
      "Ludzie uczÄ… siÄ™ tych powiÄ…zaÅ„ naturalnie, a\n",
      "dobre modele jÄ™zykowe muszÄ… odwzorowaÄ‡ tÄ™\n",
      "zmiennoÅ›Ä‡ i bogactwo jÄ™zyka, aby precyzyjnie\n",
      "oceniaÄ‡ prawdopodobieÅ„stwa sÅ‚Ã³w w zale-\n",
      "Å¼noÅ›ci od kontekstu.\n",
      "W tym miejscu warto zrobiÄ‡ maÅ‚e odstÄ™pstwo,\n",
      "by \n",
      "zastanowiÄ‡ \n",
      "siÄ™, \n",
      "co \n",
      "wÅ‚aÅ›ciwie \n",
      "znaczy\n",
      "stwierdzenie, \n",
      "Å¼e \n",
      "\"model \n",
      "potrafi \n",
      "rozwiÄ…zaÄ‡\n",
      "zadanie\"? Proces sprowadza siÄ™ do tego, Å¼e\n",
      "podajemy modelowi tekst w formie zapytania\n",
      "(prompt), \n",
      "a \n",
      "on \n",
      "generuje \n",
      "odpowiednie\n",
      "kontynuacje. \n",
      "JeÅ›li \n",
      "te \n",
      "generowane \n",
      "treÅ›ci\n",
      "zgadzajÄ… siÄ™ z naszymi oczekiwaniami, moÅ¼emy\n",
      "uznaÄ‡, \n",
      "Å¼e \n",
      "model \n",
      "sprostaÅ‚ \n",
      "postawionemu\n",
      "zadaniu.\n",
      "Wprowadzenie do DuÅ¼ych\n",
      "Modeli JÄ™zykowych (LLM)\n",
      "2 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context = search(model, query=query1)[0][0][\"text\"]\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5039b88",
   "metadata": {},
   "source": [
    "Context is wrong, however there is information about the query in doc.\n",
    "\n",
    "Let's try with easier query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2e43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generatywne modele grafiki komputerowej, w tym Pix2Pix, sÄ… dobre do generowania sztuki, projektowania i produkcji treÅ›ci multimedialnych.\n"
     ]
    }
   ],
   "source": [
    "query2 = (\n",
    "    \"Jaki model jest dobry do generowania sztuki, np. do materiaÅ‚Ã³w marketingowych?\"\n",
    ")\n",
    "response2 = rag(model, query2)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6454935",
   "metadata": {},
   "source": [
    "For that query, model halucinated. The answer should be Blue Willow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a0133a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inne modele sztucznej\n",
      "inteligencji\n",
      "1 6\n",
      "Generatywne modele grafiki\n",
      "komputerowej:\n",
      "Pix2Pix: Ten model jest wykorzystywany do\n",
      "konwersji obrazÃ³w z jednej dziedziny na obrazy\n",
      "w innej. Na przykÅ‚ad moÅ¼e przeksztaÅ‚caÄ‡ obrazy\n",
      "czarnobiaÅ‚e na kolorowe, rysunki w realistyczne\n",
      "obrazy, itp.\n",
      "Sztuczna \n",
      "inteligencja \n",
      "generatywna \n",
      "ma\n",
      "potencjaÅ‚ zastosowania w wielu dziedzinach,\n",
      "takich jak: sztuka, projektowanie, produkcja\n",
      "treÅ›ci multimedialnych, czy nawet medycyna.\n",
      "JednakÅ¼e, \n",
      "rÃ³wnoczeÅ›nie \n",
      "z \n",
      "zastosowaniami\n",
      "pozytywnymi, pojawiajÄ… siÄ™ takÅ¼e wyzwania\n",
      "zwiÄ…zane z etykÄ… i bezpieczeÅ„stwem, zwÅ‚aszcza\n",
      "w \n",
      "kontekÅ›cie \n",
      "faÅ‚szywych \n",
      "informacji \n",
      "i\n",
      "deepfake'Ã³w.\n",
      "Sztuczna inteligencja dedukcyjna:\n",
      "Skoncentrowana na wykorzystywaniu reguÅ‚\n",
      "logicznych \n",
      "do \n",
      "wyciÄ…gania \n",
      "wnioskÃ³w \n",
      "i\n",
      "podejmowania decyzji. Ten rodzaj AI dziaÅ‚a na\n",
      "podstawie dostarczonych danych i reguÅ‚, nie\n",
      "wymaga eksploracyjnego uczenia siÄ™.\n",
      "Sztuczna inteligencja indukcyjna: \n",
      "Oparta na zdolnoÅ›ci do wyciÄ…gania ogÃ³lnych\n",
      "zasad lub wnioskÃ³w na podstawie konkretnych\n",
      "przykÅ‚adÃ³w. Indukcyjna sztuczna inteligencja\n",
      "ma \n",
      "zdolnoÅ›Ä‡ \n",
      "uczenia \n",
      "siÄ™ \n",
      "na \n",
      "podstawie\n",
      "doÅ›wiadczeÅ„ i dostarczonych danych.\n",
      "Sztuczna \n",
      "inteligencja \n",
      "uczenia\n",
      "maszynowego (Machine Learning - ML): \n",
      "To \n",
      "obszar \n",
      "AI, \n",
      "ktÃ³ry \n",
      "umoÅ¼liwia \n",
      "systemom\n",
      "komputerowym naukÄ™ bez bezpoÅ›redniego\n",
      "programowania. \n",
      "Algorytmy \n",
      "uczenia\n",
      "maszynowego \n",
      "pozwalajÄ… \n",
      "maszynom\n",
      "samodzielnie dostosowywaÄ‡ siÄ™ do nowych\n",
      "danych i poprawiaÄ‡ swoje dziaÅ‚ania w czasie.\n",
      "Sztuczna inteligencja uczenia gÅ‚Ä™bokiego\n",
      "(Deep Learning): \n",
      "Jest to rodzaj uczenia maszynowego, w ktÃ³rym\n",
      "modele (zwane sieciami neuronowymi) skÅ‚adajÄ…\n",
      "siÄ™ z wielu warstw (stÄ…d \"gÅ‚Ä™bokie\") i sÄ… w stanie\n",
      "przetwarzaÄ‡ zÅ‚oÅ¼one dane, takie jak obrazy czy\n",
      "dÅºwiÄ™ki.\n",
      "Sztuczna inteligencja ewolucyjna: \n",
      "InspirujÄ…c siÄ™ procesami ewolucji biologicznej,\n",
      "sztuczna inteligencja ewolucyjna wykorzystuje\n",
      "algorytmy \n",
      "genetyczne \n",
      "do \n",
      "ewoluowania\n",
      "programÃ³w \n",
      "komputerowych \n",
      "w \n",
      "kierunku\n",
      "rozwiÄ…zania konkretnego problemu.\n",
      "Sztuczna inteligencja probabilistyczna:\n",
      "Obejmuje \n",
      "modelowanie \n",
      "niepewnoÅ›ci \n",
      "i\n",
      "prawdopodobieÅ„stw w procesie podejmowania\n",
      "decyzji. \n",
      "Wykorzystuje \n",
      "rachunek\n",
      "prawdopodobieÅ„stwa \n",
      "w \n",
      "analizie \n",
      "danych \n",
      "i\n",
      "przewidywaniu wynikÃ³w.\n",
      "Sztuczna inteligencja oparta na reguÅ‚ach:\n",
      "Wykorzystuje zestawy reguÅ‚ logicznych do\n",
      "podejmowania decyzji. Systemy te sÄ… zazwyczaj\n",
      "uÅ¼ywane w problemach, gdzie istnieje jasny\n",
      "zestaw reguÅ‚ i zaleÅ¼noÅ›ci.\n",
      "Sztuczna inteligencja interakcyjna: \n",
      "Skupiona \n",
      "na \n",
      "zdolnoÅ›ci \n",
      "do \n",
      "interakcji \n",
      "z\n",
      "uÅ¼ytkownikami w sposÃ³b, ktÃ³ry przypomina\n",
      "ludzkÄ… komunikacjÄ™. Obejmuje to chatboty,\n",
      "asystentÃ³w \n",
      "wirtualnych \n",
      "i \n",
      "systemy\n",
      "rozpoznawania mowy.\n",
      "Te rodzaje sztucznej inteligencji rÃ³Å¼niÄ… siÄ™ w\n",
      "swoich \n",
      "podejÅ›ciach, \n",
      "zastosowaniach \n",
      "i\n",
      "zdolnoÅ›ciach, \n",
      "co \n",
      "umoÅ¼liwia \n",
      "dostosowanie\n",
      "technologii do rÃ³Å¼nych problemÃ³w i dziedzin.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "context2 = search(model, query=query2)[0][0][\"text\"]\n",
    "print(context2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fe7ae3",
   "metadata": {},
   "source": [
    "Again, wrong context were parsed. I assume this is caused because of metric_type=\"L2\", which is very bad for high dimensional spaces (in this case 784).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f2dec",
   "metadata": {},
   "source": [
    "## Second try with cosine metric\n",
    "\n",
    "Create similar collection to above but with cosine_similarity metric_type and try search for the same queries again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29ee0d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rag_texts_and_embeddings_cosine', 'rag_texts_and_embeddings']\n",
      "{'collection_name': 'rag_texts_and_embeddings_cosine', 'auto_id': True, 'num_shards': 1, 'description': 'RAG Texts collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': 'Primary id', 'type': <DataType.INT64: 5>, 'params': {}, 'auto_id': True, 'is_primary': True}, {'field_id': 101, 'name': 'text', 'description': 'Page text', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 4096}}, {'field_id': 102, 'name': 'embedding', 'description': 'Embedded text', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 768}}], 'functions': [], 'aliases': [], 'collection_id': 461835363954033315, 'consistency_level': 2, 'properties': {}, 'num_partitions': 1, 'enable_dynamic_field': True, 'created_timestamp': 461835861047115779}\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_NAME_COSINE = \"rag_texts_and_embeddings_cosine\"\n",
    "\n",
    "milvus_client.create_collection(collection_name=COLLECTION_NAME_COSINE, schema=schema)\n",
    "\n",
    "index_params_cosine = milvus_client.prepare_index_params()\n",
    "\n",
    "index_params_cosine.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"HNSW\",\n",
    "    metric_type=\"COSINE\",\n",
    "    params={\"M\": 4, \"efConstruction\": 64},  # lower values for speed\n",
    ")\n",
    "\n",
    "\n",
    "milvus_client.create_index(\n",
    "    collection_name=COLLECTION_NAME_COSINE, index_params=index_params_cosine\n",
    ")\n",
    "\n",
    "# checkout our collection\n",
    "print(milvus_client.list_collections())\n",
    "\n",
    "# describe our collection\n",
    "print(milvus_client.describe_collection(COLLECTION_NAME_COSINE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "68f526bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_embeddings(file_json, embeddings_json, collection_name=COLLECTION_NAME_COSINE)\n",
    "milvus_client.load_collection(COLLECTION_NAME_COSINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf5639",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6fa4c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nie znaleziono informacji.\n"
     ]
    }
   ],
   "source": [
    "query3 = \"Czym jest Contrastive Language-Image Pretraining?\"\n",
    "response3 = rag(\n",
    "    model, query3, collection_nane=COLLECTION_NAME_COSINE, metric_type=\"COSINE\"\n",
    ")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1b36553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WielkoÅ›Ä‡ zasobÃ³w internetowych, na podstawie\n",
      "ktÃ³rych LLM rozwija swoje moÅ¼liwoÅ›ci, staje siÄ™\n",
      "coraz wiÄ™ksza, a nad ich jakoÅ›ciÄ… czuwajÄ…\n",
      "twÃ³rcy modelu. PrzeÅ‚omem w ustanawianiu\n",
      "standardÃ³w z zakresu modelowania jÄ™zyka byÅ‚\n",
      "ChatGPT-2, ktÃ³ry pokazaÅ‚, jak zwiÄ™kszenie skali\n",
      "modelu moÅ¼e prowadziÄ‡ do nowych i bardziej\n",
      "zaawansowanych moÅ¼liwoÅ›ci. Te umiejÄ™tnoÅ›ci\n",
      "tworzenia tekstu przez GPT-2 przeÅ‚oÅ¼yÅ‚y siÄ™ na\n",
      "zdolnoÅ›Ä‡ do wytwarzania dÅ‚ugich, spÃ³jnych i\n",
      "kontekstowo poprawnych treÅ›ci, z tworzeniem\n",
      "esejÃ³w, opowiadaÅ„, a nawet poezji wÅ‚Ä…cznie.\n",
      "Model wykazaÅ‚ teÅ¼ zdolnoÅ›Ä‡ do rozumienia i\n",
      "rozwiÄ…zywania \n",
      "bardziej \n",
      "zÅ‚oÅ¼onych \n",
      "zadaÅ„\n",
      "jÄ™zykowych, \n",
      "takich \n",
      "jak \n",
      "rozrÃ³Å¼nianie\n",
      "dwuznacznoÅ›ci \n",
      "w \n",
      "tekstach. \n",
      "Kolejne \n",
      "etapy\n",
      "rozwoju popularnego czatu doprowadziÅ‚y do\n",
      "wersji \n",
      "GPT-4, \n",
      "wykraczajÄ…cej \n",
      "juÅ¼ \n",
      "poza\n",
      "modelowanie jÄ™zykowe i obejmujÄ…cej multi-\n",
      "media.\n",
      "JeÅ›li zastanawiasz siÄ™, dlaczego ciÄ…gle mÃ³wimy\n",
      "o \"przewidywaniu jednego, kolejnego sÅ‚owa\",\n",
      "podczas gdy na przykÅ‚ad czat GPT bez trudu\n",
      "generuje dÅ‚ugie teksty, to odpowiedÅº jest\n",
      "prosta: modele jÄ™zykowe faktycznie generujÄ…\n",
      "dÅ‚ugie teksty, ale robiÄ… to krok po kroku, sÅ‚owo\n",
      "po sÅ‚owie. W rzeczywistoÅ›ci, po wygenerowaniu\n",
      "kaÅ¼dego \n",
      "nowego \n",
      "sÅ‚owa, \n",
      "model \n",
      "ponownie\n",
      "przetwarza caÅ‚y poprzedni tekst wraz z nowo\n",
      "dodanym \n",
      "fragmentem, \n",
      "aby \n",
      "wygenerowaÄ‡\n",
      "kolejne sÅ‚owo. W ten sposÃ³b powstaje spÃ³jna\n",
      "wypowiedÅº.\n",
      "W rzeczywistoÅ›ci duÅ¼e modele jÄ™zykowe (LLM)\n",
      "starajÄ… siÄ™ przewidzieÄ‡ nie tyle konkretne,\n",
      "nastÄ™pne \n",
      "sÅ‚owo, \n",
      "ile \n",
      "prawdopodobieÅ„stwa\n",
      "uÅ¼ycia rÃ³Å¼nych sÅ‚Ã³w, ktÃ³re mogÄ… kontynuowaÄ‡\n",
      "dany tekst. Dlaczego najlepszym rozwiÄ…zaniem\n",
      "nie \n",
      "zawsze \n",
      "jest \n",
      "szukanie \n",
      "\"najbardziej\n",
      "odpowiedniego\" \n",
      "sÅ‚owa? \n",
      "RozwaÅ¼my \n",
      "to \n",
      "na\n",
      "przykÅ‚adzie prostej gry.\n",
      "ZaÅ‚Ã³Å¼my, Å¼e masz kontynuowaÄ‡ tekst: \"44.\n",
      "prezydent USA (i pierwszy Afroamerykanin na\n",
      "tym stanowisku) to Barack...\". JeÅ›li pomyÅ›laÅ‚eÅ›,\n",
      "Å¼e nastÄ™pnym sÅ‚owem powinno byÄ‡ \"Obama\" z\n",
      "prawdopodobieÅ„stwem 100%, to siÄ™ mylisz! W\n",
      "oficjalnych \n",
      "dokumentach \n",
      "imiÄ™ \n",
      "prezydenta\n",
      "czÄ™sto jest podawane w wersji peÅ‚nej, razem z\n",
      "drugim imieniem \"Hussein\". Dlatego dobrze\n",
      "wytrenowany LLM przewidziaÅ‚by \"Obama\" z\n",
      "prawdopodobieÅ„stwem \n",
      "okoÅ‚o \n",
      "90%, \n",
      "pozo-\n",
      "stawiajÄ…c 10% dla \"Hussein\".\n",
      "To obrazuje interesujÄ…cy aspekt LLM â€“ jego\n",
      "twÃ³rczy \n",
      "charakter. \n",
      "Podczas \n",
      "generowania\n",
      "kaÅ¼dego nastÄ™pnego sÅ‚owa, modele wybierajÄ…\n",
      "je \"losowo\" bazujÄ…c na prawdopodobieÅ„stwach\n",
      "wyliczonych \n",
      "podczas \n",
      "treningu \n",
      "na \n",
      "duÅ¼ych\n",
      "zbiorach tekstÃ³w. DziÄ™ki temu, te same modele\n",
      "mogÄ… dawaÄ‡ rÃ³Å¼ne odpowiedzi na identyczne\n",
      "zapytania, podobnie jak ludzie. Eksperymenty\n",
      "pokazaÅ‚y, \n",
      "Å¼e \n",
      "modele \n",
      "wybierajÄ…ce \n",
      "zawsze\n",
      "\"najbardziej prawdopodobne\" sÅ‚owo dziaÅ‚ajÄ…\n",
      "gorzej niÅ¼ te, ktÃ³re wprowadzajÄ… element\n",
      "losowoÅ›ci.\n",
      "JÄ™zyk jest strukturÄ… z zasadami i wyjÄ…tkami, a\n",
      "sÅ‚owa w zdaniach sÄ… ze sobÄ… powiÄ…zane. \n",
      "Ludzie uczÄ… siÄ™ tych powiÄ…zaÅ„ naturalnie, a\n",
      "dobre modele jÄ™zykowe muszÄ… odwzorowaÄ‡ tÄ™\n",
      "zmiennoÅ›Ä‡ i bogactwo jÄ™zyka, aby precyzyjnie\n",
      "oceniaÄ‡ prawdopodobieÅ„stwa sÅ‚Ã³w w zale-\n",
      "Å¼noÅ›ci od kontekstu.\n",
      "W tym miejscu warto zrobiÄ‡ maÅ‚e odstÄ™pstwo,\n",
      "by \n",
      "zastanowiÄ‡ \n",
      "siÄ™, \n",
      "co \n",
      "wÅ‚aÅ›ciwie \n",
      "znaczy\n",
      "stwierdzenie, \n",
      "Å¼e \n",
      "\"model \n",
      "potrafi \n",
      "rozwiÄ…zaÄ‡\n",
      "zadanie\"? Proces sprowadza siÄ™ do tego, Å¼e\n",
      "podajemy modelowi tekst w formie zapytania\n",
      "(prompt), \n",
      "a \n",
      "on \n",
      "generuje \n",
      "odpowiednie\n",
      "kontynuacje. \n",
      "JeÅ›li \n",
      "te \n",
      "generowane \n",
      "treÅ›ci\n",
      "zgadzajÄ… siÄ™ z naszymi oczekiwaniami, moÅ¼emy\n",
      "uznaÄ‡, \n",
      "Å¼e \n",
      "model \n",
      "sprostaÅ‚ \n",
      "postawionemu\n",
      "zadaniu.\n",
      "Wprowadzenie do DuÅ¼ych\n",
      "Modeli JÄ™zykowych (LLM)\n",
      "2 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "contxet3 = search(\n",
    "    model, query3, collection_name=COLLECTION_NAME_COSINE, metric_type=\"COSINE\"\n",
    ")\n",
    "\n",
    "print(contxet3[0][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a19d7c8",
   "metadata": {},
   "source": [
    "Again same issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98eb7017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na podstawie dostarczonego kontekstu, dobrym modelem do generowania sztuki, np. do materiaÅ‚Ã³w marketingowych, jest **Pix2Pix**, naleÅ¼Ä…cy do kategorii generatywnych modeli grafiki komputerowej. W kontekÅ›cie wspomniano, Å¼e sztuczna inteligencja generatywna ma potencjaÅ‚ zastosowania w sztuce, projektowaniu i produkcji treÅ›ci multimedialnych.\n"
     ]
    }
   ],
   "source": [
    "query4 = (\n",
    "    \"Jaki model jest dobry do generowania sztuki, np. do materiaÅ‚Ã³w marketingowych?\"\n",
    ")\n",
    "response4 = rag(\n",
    "    model, query4, collection_nane=COLLECTION_NAME_COSINE, metric_type=\"COSINE\"\n",
    ")\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245c50e",
   "metadata": {},
   "source": [
    "Again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9beedee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwszy etap, czyli preprodukcja, to faza planowania. Obejmuje ona:\n",
      "\n",
      "1.  Zdefiniowanie celu, pomysÅ‚u, koncepcji.\n",
      "2.  Zaplanowanie budÅ¼etu.\n",
      "3.  PodjÄ™cie decyzji nt. metody produkcji, rodzaju wideo lub gatunku filmowego.\n",
      "\n",
      "Na zakoÅ„czenie tego etapu powinno siÄ™ dysponowaÄ‡ scenariuszem, scenopisem, harmonogramem, zdefiniowanym budÅ¼etem i wybranymi narzÄ™dziami potrzebnymi do produkcji i postprodukcji.\n"
     ]
    }
   ],
   "source": [
    "query5 = \"O co chodzi w pierwszym etapie, czyli preprodukcji?. Co ona zawiera??\"\n",
    "response5 = rag(\n",
    "    model, query5, collection_nane=COLLECTION_NAME_COSINE, metric_type=\"COSINE\"\n",
    ")\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f36579fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pierwszy etap, czyli preprodukcja, to faza planowania. Obejmuje ona:\n",
      "\n",
      "1.  Zdefiniowanie celu, pomysÅ‚u, koncepcji.\n",
      "2.  Zaplanowanie budÅ¼etu.\n",
      "3.  PodjÄ™cie decyzji dotyczÄ…cych metody produkcji, rodzaju wideo lub gatunku filmowego.\n",
      "\n",
      "Na zakoÅ„czenie tego etapu powinno siÄ™ dysponowaÄ‡ scenariuszem, scenopisem, harmonogramem, zdefiniowanym budÅ¼etem i wybranymi narzÄ™dziami potrzebnymi do produkcji i postprodukcji.\n"
     ]
    }
   ],
   "source": [
    "query5 = \"O co chodzi w pierwszym etapie, czyli preprodukcji?. Co ona zawiera??\"\n",
    "response5 = rag(model, query5)\n",
    "print(response5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778ac76",
   "metadata": {},
   "source": [
    "With very specified question it was finally able to find answer for the question.\n",
    "\n",
    "Overall: RAG is hard."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
